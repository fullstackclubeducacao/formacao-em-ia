#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Sistema Avan√ßado de Transcri√ß√£o e An√°lise de V√≠deos Educacionais
Mant√©m 100% de compatibilidade com o sistema original transcribe.py
Adiciona funcionalidades inteligentes de an√°lise e organiza√ß√£o

Autor: Sistema Full Stack Club
Vers√£o: 2.0.0
"""

import os
import sys
import json
import subprocess
import math
import time
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass

# Importa√ß√µes condicionais para n√£o quebrar o sistema se n√£o tiver as depend√™ncias
try:
    from google import genai
    from google.genai import types
    from pydantic import BaseModel, Field
    from typing import List, Dict, Optional
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("‚ö†Ô∏è  Google Gemini n√£o instalado. Funcionalidades de an√°lise desabilitadas.")
    print("   Para instalar: pip install google-genai pydantic")

try:
    from groq import Groq
    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False
    print("‚ùå Groq n√£o instalado. Sistema de transcri√ß√£o n√£o funcionar√°.")
    sys.exit(1)

# --- CONFIGURA√á√ïES DIN√ÇMICAS ---
# Todas as configura√ß√µes podem ser alteradas via vari√°veis de ambiente

# Configura√ß√µes de Transcri√ß√£o
CHUNK_DURATION_SECONDS = int(os.environ.get("CHUNK_SIZE_SECONDS", "600"))  # 10 minutos padr√£o
GROQ_MODEL = os.environ.get("GROQ_MODEL", "whisper-large-v3-turbo")
GROQ_LANGUAGE = os.environ.get("GROQ_LANGUAGE", "pt")

# Configura√ß√µes de Sistema
REQUEST_TIMEOUT = int(os.environ.get("REQUEST_TIMEOUT", "300"))  # 5 minutos
MAX_RETRIES = int(os.environ.get("MAX_RETRIES", "3"))
DEBUG_MODE = os.environ.get("DEBUG_MODE", "false").lower() == "true"
SAVE_DEBUG_FILES = os.environ.get("SAVE_DEBUG_FILES", "false").lower() == "true"

# Caminhos de Sistema
FFMPEG_PATH = os.environ.get("FFMPEG_PATH", "./bin/ffmpeg")
FFPROBE_PATH = os.environ.get("FFPROBE_PATH", "./bin/ffprobe")
TEMP_DIR = os.environ.get("TEMP_DIR_NAME", "temp")
OUTPUT_BASE_DIR = os.environ.get("OUTPUT_BASE_DIR", "modulo-{modulo:02d}")
VIDEOS_DIR = os.environ.get("VIDEOS_DIR", "videos")

# Configura√ß√µes de √Åudio
AUDIO_SAMPLE_RATE = int(os.environ.get("AUDIO_SAMPLE_RATE", "16000"))
AUDIO_CHANNELS = int(os.environ.get("AUDIO_CHANNELS", "1"))
AUDIO_FORMAT = os.environ.get("AUDIO_FORMAT", "flac")

# Padr√µes de Diret√≥rio
AULA_DIR_PATTERN = os.environ.get("AULA_DIR_PATTERN", "aula-{numero:02d}-{slug}")

@dataclass
class TranscriptionResult:
    """Resultado da transcri√ß√£o"""
    text: str
    segments: List[Dict]
    words: List[Dict]
    duration: float
    metadata: Dict[str, Any]

# --- MODELOS PYDANTIC PARA STRUCTURED OUTPUT ---
if GEMINI_AVAILABLE:
    class Conceito(BaseModel):
        conceito: str = Field(description="Nome do conceito t√©cnico")
        definicao: str = Field(description="Explica√ß√£o clara e concisa do conceito")

    class AnalysisSchema(BaseModel):
        titulo_sugerido: str = Field(description="T√≠tulo descritivo e profissional da aula")
        resumo_executivo: str = Field(description="Resumo conciso em 2-3 par√°grafos sobre o conte√∫do principal")
        pontos_chave: List[str] = Field(description="Lista de 3-5 pontos mais importantes da aula", min_items=3, max_items=5)
        tecnologias_mencionadas: List[str] = Field(description="Tecnologias, frameworks, ferramentas mencionadas")
        comandos_codigo: List[str] = Field(description="Comandos de terminal, c√≥digo ou scripts mencionados")
        conceitos_importantes: List[Conceito] = Field(description="Conceitos t√©cnicos importantes explicados na aula")
        nivel_dificuldade: str = Field(description="N√≠vel de dificuldade: b√°sico, intermedi√°rio ou avan√ßado")
        duracao_estimada: str = Field(description="Dura√ß√£o estimada da aula em minutos")
        pre_requisitos: List[str] = Field(description="Conhecimentos pr√©vios necess√°rios")
        objetivos_aprendizado: List[str] = Field(description="O que o aluno aprender√° ao final da aula")
        tags: List[str] = Field(description="Tags relevantes para categoriza√ß√£o e busca")
        
        class Config:
            title = "An√°lise de Aula T√©cnica"
            description = "Estrutura completa de an√°lise de conte√∫do educacional t√©cnico"

@dataclass
class AnalysisResult:
    """Resultado da an√°lise (compatibilidade com c√≥digo existente)"""
    titulo_sugerido: str
    resumo_executivo: str
    pontos_chave: List[str]
    tecnologias_mencionadas: List[str]
    comandos_codigo: List[str]
    conceitos_importantes: List[Dict[str, str]]
    nivel_dificuldade: str
    duracao_estimada: str
    pre_requisitos: List[str]
    objetivos_aprendizado: List[str]
    tags: List[str]

# --- FUN√á√ïES DE DEBUG ---

def debug_print(message: str):
    """Print debug se modo debug estiver ativo"""
    if DEBUG_MODE:
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"üêõ [{timestamp}] {message}")

def save_debug_file(content: Any, filename: str):
    """Salva arquivo de debug se habilitado"""
    if SAVE_DEBUG_FILES:
        debug_dir = os.path.join(TEMP_DIR, "debug")
        os.makedirs(debug_dir, exist_ok=True)
        debug_path = os.path.join(debug_dir, filename)
        
        if isinstance(content, (dict, list)):
            with open(debug_path, "w", encoding="utf-8") as f:
                json.dump(content, f, ensure_ascii=False, indent=2)
        else:
            with open(debug_path, "w", encoding="utf-8") as f:
                f.write(str(content))
        
        debug_print(f"Debug file saved: {debug_path}")

# --- FUN√á√ïES ORIGINAIS MANTIDAS ---

def get_audio_duration(file_path: str) -> Optional[float]:
    """
    Obt√©m a dura√ß√£o de um arquivo de m√≠dia usando ffprobe.
    FUN√á√ÉO ORIGINAL MANTIDA INTACTA COM CONFIGURA√á√ïES DIN√ÇMICAS
    """
    command = [
        FFPROBE_PATH,
        "-v", "error",
        "-show_entries", "format=duration",
        "-of", "default=noprint_wrappers=1:nokey=1",
        file_path
    ]
    try:
        result = subprocess.run(command, check=True, capture_output=True, text=True, timeout=REQUEST_TIMEOUT)
        duration = float(result.stdout)
        debug_print(f"Audio duration: {duration:.2f}s for {file_path}")
        return duration
    except (subprocess.CalledProcessError, ValueError, subprocess.TimeoutExpired) as e:
        print(f"Erro ao obter a dura√ß√£o do √°udio de {file_path}: {e}")
        return None

def transcribe_video_original(video_path: str) -> Optional[Dict[str, Any]]:
    """
    FUN√á√ÉO ORIGINAL DE TRANSCRI√á√ÉO MANTIDA 100% INTACTA COM CONFIGURA√á√ïES DIN√ÇMICAS
    Transcreve um arquivo de v√≠deo usando a API Groq, dividindo o √°udio em peda√ßos (chunks) se necess√°rio.
    """
    print(f"Iniciando o processo para: {video_path}")
    debug_print(f"Configura√ß√µes: CHUNK_SIZE={CHUNK_DURATION_SECONDS}s, MODEL={GROQ_MODEL}, LANG={GROQ_LANGUAGE}")

    # 1. Validar API Key
    api_key = os.environ.get("GROQ_API_KEY")
    if not api_key:
        print("Erro: A vari√°vel de ambiente GROQ_API_KEY n√£o foi encontrada.")
        return None
    client = Groq(api_key=api_key)

    # 2. Preparar caminhos
    base_name = os.path.basename(video_path)
    file_name, _ = os.path.splitext(base_name)
    temp_dir = TEMP_DIR
    os.makedirs(temp_dir, exist_ok=True)
    final_transcription_path = os.path.join(temp_dir, f"{file_name}_transcription.json")

    # 3. Obter dura√ß√£o e calcular chunks
    duration = get_audio_duration(video_path)
    if duration is None:
        return None
    
    num_chunks = math.ceil(duration / CHUNK_DURATION_SECONDS)
    print(f"Dura√ß√£o do v√≠deo: {duration:.2f}s. Dividindo em {num_chunks} peda√ßo(s).")

    all_segments = []
    total_words = []
    transcribed_duration = 0.0

    for i in range(num_chunks):
        chunk_num = i + 1
        start_time = i * CHUNK_DURATION_SECONDS
        chunk_audio_path = os.path.join(temp_dir, f"{file_name}_chunk_{chunk_num}.{AUDIO_FORMAT}")
        
        print(f"\n--- Processando Peda√ßo {chunk_num}/{num_chunks} ---")
        print(f"Convertendo √°udio (in√≠cio: {start_time}s)...")

        # 4. Converter um peda√ßo do v√≠deo para √°udio com configura√ß√µes din√¢micas
        ffmpeg_command = [
            FFMPEG_PATH,
            "-i", video_path,
            "-ss", str(start_time),
            "-t", str(CHUNK_DURATION_SECONDS),
            "-vn", 
            "-ar", str(AUDIO_SAMPLE_RATE), 
            "-ac", str(AUDIO_CHANNELS), 
            "-c:a", AUDIO_FORMAT,
            "-y", chunk_audio_path
        ]
        
        debug_print(f"FFmpeg command: {' '.join(ffmpeg_command)}")
        
        try:
            result = subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True, timeout=REQUEST_TIMEOUT)
            debug_print(f"FFmpeg success for chunk {chunk_num}")
            if SAVE_DEBUG_FILES:
                save_debug_file(result.stderr, f"ffmpeg_chunk_{chunk_num}_output.log")
        except subprocess.CalledProcessError as e:
            print(f"Erro no ffmpeg para o peda√ßo {chunk_num}: {e.stderr}")
            save_debug_file(str(e), f"ffmpeg_chunk_{chunk_num}_error.log")
            continue # Pula para o pr√≥ximo peda√ßo
        except subprocess.TimeoutExpired:
            print(f"Timeout no ffmpeg para o peda√ßo {chunk_num}")
            continue

        # 5. Transcrever o peda√ßo com a API
        print(f"Enviando peda√ßo {chunk_num} para a API do Groq...")
        
        retry_count = 0
        transcription = None
        
        while retry_count < MAX_RETRIES and transcription is None:
            try:
                with open(chunk_audio_path, "rb") as file:
                    transcription = client.audio.transcriptions.create(
                        file=(os.path.basename(chunk_audio_path), file.read()),
                        model=GROQ_MODEL,
                        response_format="verbose_json",
                        timestamp_granularities=["word", "segment"],
                        language=GROQ_LANGUAGE
                    ).to_dict()

                # Acumular resultados, ajustando timestamps
                for segment in transcription.get('segments', []):
                    segment['start'] += start_time
                    segment['end'] += start_time
                    all_segments.append(segment)
                
                for word in transcription.get('words', []):
                    word['start'] += start_time
                    word['end'] += start_time
                    total_words.append(word)

                chunk_transcribed_duration = transcription.get('duration', 0)
                transcribed_duration += chunk_transcribed_duration
                print(f"Peda√ßo {chunk_num} transcrito com sucesso.")
                
                # Salvar debug da transcri√ß√£o
                if SAVE_DEBUG_FILES:
                    save_debug_file(transcription, f"transcription_chunk_{chunk_num}.json")

            except Exception as e:
                retry_count += 1
                print(f"Erro na transcri√ß√£o do peda√ßo {chunk_num} (tentativa {retry_count}/{MAX_RETRIES}): {e}")
                save_debug_file(str(e), f"transcription_chunk_{chunk_num}_error_{retry_count}.log")
                
                if retry_count < MAX_RETRIES:
                    wait_time = 2 ** retry_count  # Backoff exponencial
                    print(f"Aguardando {wait_time}s antes da pr√≥xima tentativa...")
                    time.sleep(wait_time)
        
        # Limpar arquivo tempor√°rio ap√≥s tentativas (a menos que esteja em modo debug)
        if os.path.exists(chunk_audio_path) and not SAVE_DEBUG_FILES:
            os.remove(chunk_audio_path)
        elif SAVE_DEBUG_FILES:
            debug_print(f"Chunk file preserved for debug: {chunk_audio_path}")

    # 6. Montar o JSON final
    full_text = " ".join([word['word'] for word in total_words])
    final_result = {
        "text": full_text.strip(),
        "segments": all_segments,
        "words": total_words,
        "duration": transcribed_duration,
        "metadata": {
            "original_file": video_path,
            "chunks_processed": num_chunks,
            "model_used": GROQ_MODEL,
            "language": GROQ_LANGUAGE,
            "chunk_size_seconds": CHUNK_DURATION_SECONDS,
            "processed_at": datetime.now().isoformat()
        }
    }

    with open(final_transcription_path, "w", encoding="utf-8") as f:
        json.dump(final_result, f, ensure_ascii=False, indent=2)

    print(f"\n--- Processo Conclu√≠do ---")
    print(f"Transcri√ß√£o final combinada e salva em: {final_transcription_path}")
    
    debug_print(f"Final stats: {len(total_words)} words, {len(all_segments)} segments, {transcribed_duration:.2f}s")
    
    return final_result

# --- NOVAS FUNCIONALIDADES ENHANCED ---

class EnhancedTranscriptionSystem:
    """Sistema avan√ßado de transcri√ß√£o e an√°lise de conte√∫do educacional"""
    
    def __init__(self):
        self.setup_apis()
        # N√£o criar diret√≥rios automaticamente - apenas quando processar v√≠deos
        
    def setup_apis(self):
        """Configura as APIs necess√°rias"""
        # Groq para transcri√ß√£o
        self.groq_api_key = os.environ.get("GROQ_API_KEY")
        if not self.groq_api_key:
            print("‚ùå GROQ_API_KEY n√£o encontrada")
            self.groq_available = False
        else:
            try:
                self.groq_client = Groq(api_key=self.groq_api_key)
                self.groq_available = True
                print("‚úÖ Groq configurado")
            except Exception as e:
                print(f"‚ùå Erro ao configurar Groq: {e}")
                self.groq_available = False
        
        # Gemini para an√°lise (opcional)
        self.gemini_api_key = os.environ.get("GEMINI_API_KEY")
        if not self.gemini_api_key or not GEMINI_AVAILABLE:
            print("‚ö†Ô∏è  GEMINI_API_KEY n√£o encontrada ou biblioteca n√£o instalada")
            print("   Funcionalidades de an√°lise inteligente desabilitadas")
            self.gemini_available = False
        else:
            try:
                # Configurar cliente Gemini com nova API
                self.gemini_client = genai.Client(api_key=self.gemini_api_key)
                
                # Configura√ß√µes opcionais do ambiente
                self.gemini_model = os.environ.get("GEMINI_MODEL", "gemini-2.5-flash")
                self.thinking_enabled = os.environ.get("GEMINI_THINKING", "true").lower() == "true"
                self.thinking_budget = int(os.environ.get("GEMINI_THINKING_BUDGET", "-1"))  # -1 = din√¢mico
                self.max_context = int(os.environ.get("GEMINI_MAX_CONTEXT", "1000000"))  # 1M tokens por padr√£o
                
                print(f"‚úÖ Gemini configurado: {self.gemini_model}")
                if self.thinking_enabled:
                    print(f"üß† Thinking habilitado (budget: {self.thinking_budget})")
                else:
                    print("‚ö° Thinking desabilitado para performance")
                print(f"üìÑ Contexto m√°ximo: {self.max_context:,} tokens")
                
                self.gemini_available = True
            except Exception as e:
                print(f"‚ùå Erro ao configurar Gemini: {e}")
                self.gemini_available = False
        
    def ensure_directories(self):
        """Garante que os diret√≥rios necess√°rios existam"""
        os.makedirs(TEMP_DIR, exist_ok=True)
        os.makedirs("videos", exist_ok=True)
        
    def transcribe_video(self, video_path: str) -> Optional[TranscriptionResult]:
        """
        Transcreve v√≠deo usando a fun√ß√£o original
        """
        if not self.groq_available:
            print("‚ùå Groq n√£o dispon√≠vel. N√£o √© poss√≠vel transcrever.")
            return None
            
        result = transcribe_video_original(video_path)
        if not result:
            return None
            
        # Converter para TranscriptionResult
        base_name = os.path.basename(video_path)
        file_name, _ = os.path.splitext(base_name)
        
        return TranscriptionResult(
            text=result["text"],
            segments=result["segments"],
            words=result["words"],
            duration=result["duration"],
            metadata={
                "file_name": file_name,
                "original_path": video_path,
                "transcription_date": datetime.now().isoformat(),
                "chunks_processed": math.ceil(result["duration"] / CHUNK_DURATION_SECONDS)
            }
        )

    def analyze_content_with_gemini(self, transcription: TranscriptionResult) -> Optional[AnalysisResult]:
        """Analisa conte√∫do transcrito usando Gemini com structured output e thinking"""
        if not self.gemini_available:
            print("‚ö†Ô∏è  Gemini n√£o dispon√≠vel. Usando an√°lise b√°sica.")
            return self._basic_analysis(transcription)
            
        # Aproveitar o contexto longo do Gemini (at√© 1M+ tokens)
        # Calcular tokens aproximados (1 token ‚âà 4 caracteres em portugu√™s)
        estimated_tokens = len(transcription.text) // 4
        
        if estimated_tokens > self.max_context:
            # Se exceder, usar estrat√©gia inteligente de truncamento
            # Manter in√≠cio e final, resumir meio
            text_start = transcription.text[:self.max_context//3 * 4]
            text_end = transcription.text[-self.max_context//3 * 4:]
            text_sample = f"{text_start}\n\n[... CONTE√öDO INTERMEDI√ÅRIO OMITIDO ...]\n\n{text_end}"
            print(f"üìä Texto truncado: {estimated_tokens:,} ‚Üí {self.max_context:,} tokens")
        else:
            text_sample = transcription.text
            print(f"üìä Processando {estimated_tokens:,} tokens de contexto")

        # System instruction otimizada para an√°lise educacional
        system_instruction = """Voc√™ √© um especialista em an√°lise de conte√∫do educacional t√©cnico. 
        Sua fun√ß√£o √© extrair informa√ß√µes estruturadas de transcri√ß√µes de aulas t√©cnicas, 
        identificando conceitos, tecnologias, comandos e organizando o conhecimento de forma did√°tica.
        
        Seja preciso, t√©cnico e educativo. Extraia apenas informa√ß√µes que est√£o explicitamente 
        presentes na transcri√ß√£o. Mantenha consist√™ncia terminol√≥gica."""

        # Prompt otimizado para thinking e long context
        analysis_prompt = f"""Analise esta transcri√ß√£o de aula t√©cnica em portugu√™s e extraia informa√ß√µes estruturadas:

CONTEXTO DA AULA:
- Dura√ß√£o da grava√ß√£o: {transcription.duration/60:.1f} minutos
- Palavras transcritas: {len(transcription.words):,}
- Segmentos de √°udio: {len(transcription.segments)}

TRANSCRI√á√ÉO COMPLETA:
{text_sample}

INSTRU√á√ïES PARA AN√ÅLISE:
1. Leia toda a transcri√ß√£o com aten√ß√£o
2. Identifique o tema principal e subtemas
3. Extraia tecnologias, ferramentas e frameworks mencionados
4. Capture comandos de c√≥digo, terminal ou configura√ß√µes
5. Identifique conceitos t√©cnicos explicados e suas defini√ß√µes
6. Determine o n√≠vel de dificuldade baseado na complexidade dos conceitos
7. Sugira pr√©-requisitos baseado nas tecnologias e conceitos apresentados
8. Defina objetivos de aprendizado espec√≠ficos e mensur√°veis

Seja detalhado na an√°lise e precise nas informa√ß√µes extra√≠das."""

        try:
            print("üß† Iniciando an√°lise inteligente com Gemini...")
            
            # Configurar thinking se habilitado
            thinking_config = None
            if self.thinking_enabled:
                try:
                    thinking_config = types.GenerationConfigThinkingConfig(
                        thinking_budget=self.thinking_budget if self.thinking_budget != -1 else None,
                        include_thoughts=False  # N√£o incluir thoughts na resposta para economizar tokens
                    )
                    print(f"üß† Using thinking with budget: {self.thinking_budget}")
                except AttributeError:
                    print("‚ö†Ô∏è  Thinking n√£o dispon√≠vel nesta vers√£o do SDK")
                    thinking_config = None
            
            # Configura√ß√£o de gera√ß√£o com structured output
            generation_config_params = {
                "response_mime_type": "application/json",
                "response_schema": AnalysisSchema,
                "temperature": 0.1,  # Baixa temperatura para consist√™ncia
                "system_instruction": system_instruction,
            }
            
            # Adicionar thinking config se dispon√≠vel
            if thinking_config:
                generation_config_params["thinking_config"] = thinking_config
            
            # Fazer a chamada para o Gemini
            response = self.gemini_client.models.generate_content(
                model=self.gemini_model,
                contents=analysis_prompt,
                config=types.GenerateContentConfig(**generation_config_params)
            )
            
            # Usar structured output direto (response.parsed)
            if hasattr(response, 'parsed') and response.parsed:
                analysis_data = response.parsed
                print("‚úÖ Structured output recebido com sucesso")
            else:
                # Fallback para parsing manual se structured output falhar
                print("‚ö†Ô∏è  Fallback para parsing manual")
                response_text = response.text.strip()
                analysis_data = json.loads(response_text)
            
            # Converter conceitos para formato compat√≠vel
            conceitos_convertidos = []
            if hasattr(analysis_data, 'conceitos_importantes'):
                for conceito in analysis_data.conceitos_importantes:
                    if hasattr(conceito, 'conceito') and hasattr(conceito, 'definicao'):
                        conceitos_convertidos.append({
                            "conceito": conceito.conceito,
                            "definicao": conceito.definicao
                        })
            elif isinstance(analysis_data, dict) and 'conceitos_importantes' in analysis_data:
                conceitos_convertidos = analysis_data['conceitos_importantes']
            
            # Converter para AnalysisResult (compatibilidade)
            if hasattr(analysis_data, 'titulo_sugerido'):
                # Objeto Pydantic
                analysis = AnalysisResult(
                    titulo_sugerido=analysis_data.titulo_sugerido,
                    resumo_executivo=analysis_data.resumo_executivo,
                    pontos_chave=analysis_data.pontos_chave,
                    tecnologias_mencionadas=analysis_data.tecnologias_mencionadas,
                    comandos_codigo=analysis_data.comandos_codigo,
                    conceitos_importantes=conceitos_convertidos,
                    nivel_dificuldade=analysis_data.nivel_dificuldade,
                    duracao_estimada=analysis_data.duracao_estimada,
                    pre_requisitos=analysis_data.pre_requisitos,
                    objetivos_aprendizado=analysis_data.objetivos_aprendizado,
                    tags=analysis_data.tags
                )
            else:
                # Dict normal
                analysis = AnalysisResult(
                    titulo_sugerido=analysis_data.get("titulo_sugerido", "Aula T√©cnica"),
                    resumo_executivo=analysis_data.get("resumo_executivo", ""),
                    pontos_chave=analysis_data.get("pontos_chave", []),
                    tecnologias_mencionadas=analysis_data.get("tecnologias_mencionadas", []),
                    comandos_codigo=analysis_data.get("comandos_codigo", []),
                    conceitos_importantes=conceitos_convertidos,
                    nivel_dificuldade=analysis_data.get("nivel_dificuldade", "intermedi√°rio"),
                    duracao_estimada=analysis_data.get("duracao_estimada", f"{int(transcription.duration//60)} minutos"),
                    pre_requisitos=analysis_data.get("pre_requisitos", []),
                    objetivos_aprendizado=analysis_data.get("objetivos_aprendizado", []),
                    tags=analysis_data.get("tags", [])
                )
            
            # Mostrar estat√≠sticas do uso
            if hasattr(response, 'usage_metadata'):
                usage = response.usage_metadata
                print(f"üìä Tokens utilizados:")
                print(f"   ‚Ä¢ Input: {usage.prompt_token_count:,}")
                print(f"   ‚Ä¢ Output: {usage.candidates_token_count:,}")
                if hasattr(usage, 'thoughts_token_count') and usage.thoughts_token_count:
                    print(f"   ‚Ä¢ Thinking: {usage.thoughts_token_count:,}")
                print(f"   ‚Ä¢ Total: {usage.total_token_count:,}")
            
            print("‚úÖ An√°lise inteligente conclu√≠da com sucesso")
            return analysis
            
        except Exception as e:
            print(f"‚ùå Erro na an√°lise Gemini: {e}")
            print("üîÑ Tentando an√°lise b√°sica como fallback...")
            return self._basic_analysis(transcription)

    def _basic_analysis(self, transcription: TranscriptionResult) -> AnalysisResult:
        """An√°lise b√°sica quando Gemini n√£o est√° dispon√≠vel"""
        file_name = transcription.metadata.get("file_name", "Aula")
        
        # Extrair algumas informa√ß√µes b√°sicas do texto
        text = transcription.text.lower()
        
        # Detectar tecnologias comuns
        tech_keywords = {
            "docker": "Docker",
            "n8n": "N8N", 
            "postgres": "PostgreSQL",
            "redis": "Redis",
            "traefik": "Traefik",
            "portainer": "Portainer",
            "javascript": "JavaScript",
            "python": "Python",
            "nodejs": "Node.js",
            "react": "React",
            "vue": "Vue.js",
            "api": "API",
            "webhook": "Webhook",
            "json": "JSON",
            "sql": "SQL",
            "html": "HTML",
            "css": "CSS"
        }
        
        detected_techs = []
        for keyword, tech_name in tech_keywords.items():
            if keyword in text:
                detected_techs.append(tech_name)
        
        # Detectar comandos b√°sicos
        command_patterns = [
            r'docker\s+\w+',
            r'npm\s+\w+',
            r'pip\s+\w+',
            r'git\s+\w+',
            r'sudo\s+\w+',
            r'chmod\s+\d+',
            r'mkdir\s+\w+',
            r'cd\s+\w+'
        ]
        
        detected_commands = []
        for pattern in command_patterns:
            matches = re.findall(pattern, text)
            detected_commands.extend(matches[:3])  # Limitar a 3 por padr√£o
        
        return AnalysisResult(
            titulo_sugerido=f"Aula - {file_name}",
            resumo_executivo=f"Esta aula aborda conte√∫do t√©cnico relacionado a {', '.join(detected_techs[:3]) if detected_techs else 'desenvolvimento'}. O conte√∫do tem dura√ß√£o de aproximadamente {int(transcription.duration//60)} minutos e apresenta conceitos pr√°ticos e te√≥ricos importantes para o aprendizado.",
            pontos_chave=["Conte√∫do t√©cnico pr√°tico", "Conceitos fundamentais", "Exemplos aplicados"],
            tecnologias_mencionadas=detected_techs[:5],
            comandos_codigo=detected_commands[:5],
            conceitos_importantes=[],
            nivel_dificuldade="intermedi√°rio",
            duracao_estimada=f"{int(transcription.duration//60)} minutos",
            pre_requisitos=["Conhecimento b√°sico de programa√ß√£o"],
            objetivos_aprendizado=["Compreender os conceitos apresentados", "Aplicar conhecimentos pr√°ticos"],
            tags=["aula", "t√©cnico", "programa√ß√£o"] + detected_techs[:2]
        )

    def create_slug(self, title: str) -> str:
        """Cria slug limpo a partir do t√≠tulo"""
        # Remover "Aula - " do in√≠cio se existir
        title = re.sub(r'^aula\s*-\s*', '', title, flags=re.IGNORECASE)
        
        # Substituir acentos
        replacements = {
            '√†': 'a', '√°': 'a', '√¢': 'a', '√£': 'a', '√§': 'a',
            '√®': 'e', '√©': 'e', '√™': 'e', '√´': 'e',
            '√¨': 'i', '√≠': 'i', '√Æ': 'i', '√Ø': 'i',
            '√≤': 'o', '√≥': 'o', '√¥': 'o', '√µ': 'o', '√∂': 'o',
            '√π': 'u', '√∫': 'u', '√ª': 'u', '√º': 'u',
            '√ß': 'c', '√±': 'n'
        }
        
        slug = title.lower()
        for char, replacement in replacements.items():
            slug = slug.replace(char, replacement)
        
        # Remover caracteres especiais e normalizar
        slug = re.sub(r'[^a-z0-9\s-]', '', slug)
        slug = re.sub(r'\s+', '-', slug)
        slug = re.sub(r'-+', '-', slug)
        slug = slug.strip('-')
        
        return slug[:50]  # Limitar tamanho

    def generate_directory_structure(self, analysis: AnalysisResult, modulo: int, aula: int) -> str:
        """Gera estrutura de diret√≥rios para a aula"""
        slug = self.create_slug(analysis.titulo_sugerido)
        
        modulo_dir = OUTPUT_BASE_DIR.format(modulo=modulo)
        aula_dir = os.path.join(modulo_dir, AULA_DIR_PATTERN.format(numero=aula, slug=slug))
        
        # Criar diret√≥rios
        os.makedirs(aula_dir, exist_ok=True)
        os.makedirs(os.path.join(aula_dir, "assets"), exist_ok=True)
        os.makedirs(os.path.join(aula_dir, "scripts"), exist_ok=True)
        
        return aula_dir

    def generate_readme_content(self, analysis: AnalysisResult, transcription: TranscriptionResult) -> str:
        """Gera conte√∫do do README.md"""
        
        # Pontos-chave formatados
        pontos_chave_text = "\n".join([f"‚Ä¢ **{ponto}**" for ponto in analysis.pontos_chave])
        
        # Tecnologias formatadas
        tecnologias_text = "\n".join([f"‚Ä¢ **{tech}**" for tech in analysis.tecnologias_mencionadas])
        
        # Comandos formatados
        comandos_text = ""
        if analysis.comandos_codigo:
            comandos_text = "\n## üíª Comandos Utilizados\n\n```bash\n" + "\n".join(analysis.comandos_codigo) + "\n```\n"
        
        # Conceitos importantes formatados
        conceitos_text = ""
        if analysis.conceitos_importantes:
            conceitos_text = "\n## üí° Conceitos Importantes\n\n"
            for conceito in analysis.conceitos_importantes:
                conceitos_text += f"**{conceito['conceito']}**: {conceito['definicao']}\n\n"
        
        # Pr√©-requisitos formatados
        pre_requisitos_text = ""
        if analysis.pre_requisitos:
            pre_requisitos_text = "\n## üìã Pr√©-requisitos\n\n" + "\n".join([f"‚Ä¢ {req}" for req in analysis.pre_requisitos]) + "\n"
        
        # Objetivos de aprendizado formatados
        objetivos_text = ""
        if analysis.objetivos_aprendizado:
            objetivos_text = "\n## üéØ Objetivos de Aprendizado\n\n" + "\n".join([f"‚Ä¢ {obj}" for obj in analysis.objetivos_aprendizado]) + "\n"
        
        readme_content = f"""# {analysis.titulo_sugerido}

{analysis.resumo_executivo}

## üìö Pontos-Chave

{pontos_chave_text}

## üõ†Ô∏è Tecnologias Mencionadas

{tecnologias_text}
{comandos_text}
{conceitos_text}
{pre_requisitos_text}
{objetivos_text}
## ‚è±Ô∏è Dura√ß√£o
{analysis.duracao_estimada}

## üìä Informa√ß√µes T√©cnicas
- **N√≠vel de Dificuldade**: {analysis.nivel_dificuldade.title()}
- **Palavras Transcritas**: {len(transcription.words):,}
- **Segmentos de √Åudio**: {len(transcription.segments)}
- **Dura√ß√£o Real**: {transcription.duration/60:.1f} minutos

## üè∑Ô∏è Tags
{', '.join([f'`{tag}`' for tag in analysis.tags])}

<details>
<summary>üìù Transcri√ß√£o Completa</summary>

{transcription.text}

</details>
"""
        
        return readme_content

    def save_analysis_files(self, transcription: TranscriptionResult, analysis: AnalysisResult, output_dir: str) -> List[str]:
        """Salva todos os arquivos da an√°lise"""
        files_created = []
        
        try:
            # 1. Salvar transcri√ß√£o JSON
            transcription_path = os.path.join(output_dir, "transcricao.json")
            transcription_data = {
                "text": transcription.text,
                "segments": transcription.segments,
                "words": transcription.words,
                "duration": transcription.duration,
                "metadata": transcription.metadata
            }
            with open(transcription_path, "w", encoding="utf-8") as f:
                json.dump(transcription_data, f, ensure_ascii=False, indent=2)
            files_created.append(transcription_path)
            print(f"‚úÖ Transcri√ß√£o salva: {transcription_path}")
            
            # 2. Salvar an√°lise JSON
            analysis_path = os.path.join(output_dir, "analise.json")
            analysis_data = {
                "titulo_sugerido": analysis.titulo_sugerido,
                "resumo_executivo": analysis.resumo_executivo,
                "pontos_chave": analysis.pontos_chave,
                "tecnologias_mencionadas": analysis.tecnologias_mencionadas,
                "comandos_codigo": analysis.comandos_codigo,
                "conceitos_importantes": analysis.conceitos_importantes,
                "nivel_dificuldade": analysis.nivel_dificuldade,
                "duracao_estimada": analysis.duracao_estimada,
                "pre_requisitos": analysis.pre_requisitos,
                "objetivos_aprendizado": analysis.objetivos_aprendizado,
                "tags": analysis.tags
            }
            with open(analysis_path, "w", encoding="utf-8") as f:
                json.dump(analysis_data, f, ensure_ascii=False, indent=2)
            files_created.append(analysis_path)
            print(f"‚úÖ An√°lise salva: {analysis_path}")
            
            # 3. Gerar e salvar README
            readme_content = self.generate_readme_content(analysis, transcription)
            readme_path = os.path.join(output_dir, "README.md")
            with open(readme_path, "w", encoding="utf-8") as f:
                f.write(readme_content)
            files_created.append(readme_path)
            print(f"‚úÖ README gerado: {readme_path}")
            
            # 4. Salvar comandos em arquivo separado se houver
            if analysis.comandos_codigo:
                scripts_dir = os.path.join(output_dir, "scripts")
                commands_file = os.path.join(scripts_dir, "comandos.md")
                with open(commands_file, "w", encoding="utf-8") as f:
                    f.write("# Comandos da Aula\n\n")
                    for i, cmd in enumerate(analysis.comandos_codigo, 1):
                        f.write(f"## Comando {i}\n```bash\n{cmd}\n```\n\n")
                files_created.append(commands_file)
                print(f"‚úÖ Comandos salvos: {commands_file}")
                
        except Exception as e:
            print(f"‚ùå Erro ao salvar arquivos: {e}")
            
        return files_created

    def process_video_complete(self, video_path: str, modulo: int = 1, aula: int = 1) -> Dict[str, Any]:
        """Processa um v√≠deo completamente: transcri√ß√£o + an√°lise + documenta√ß√£o"""
        print(f"\n{'='*60}")
        print(f"üöÄ PROCESSAMENTO COMPLETO - {os.path.basename(video_path)}")
        print(f"{'='*60}")
        
        try:
            # 1. Transcrever v√≠deo
            print("üìπ Etapa 1/4: Transcrevendo v√≠deo...")
            transcription = self.transcribe_video(video_path)
            if not transcription:
                return {"status": "error", "message": "Falha na transcri√ß√£o"}
            
            # 2. Analisar conte√∫do
            print("üß† Etapa 2/4: Analisando conte√∫do...")
            analysis = self.analyze_content_with_gemini(transcription)
            if not analysis:
                return {"status": "error", "message": "Falha na an√°lise"}
            
            # 3. Criar estrutura de diret√≥rios
            print("üìÅ Etapa 3/4: Criando estrutura...")
            output_dir = self.generate_directory_structure(analysis, modulo, aula)
            
            # 4. Salvar todos os arquivos
            print("üíæ Etapa 4/4: Salvando arquivos...")
            files_created = self.save_analysis_files(transcription, analysis, output_dir)
            
            result = {
                "status": "success",
                "output_dir": output_dir,
                "files_created": files_created,
                "analysis": {
                    "titulo": analysis.titulo_sugerido,
                    "nivel": analysis.nivel_dificuldade,
                    "duracao": analysis.duracao_estimada,
                    "tecnologias": len(analysis.tecnologias_mencionadas),
                    "conceitos": len(analysis.conceitos_importantes)
                },
                "transcription_stats": {
                    "duration": transcription.duration,
                    "words": len(transcription.words),
                    "segments": len(transcription.segments)
                }
            }
            
            print(f"\n‚úÖ PROCESSAMENTO CONCLU√çDO COM SUCESSO!")
            print(f"üìÅ Aula criada em: {output_dir}")
            print(f"üìä Estat√≠sticas:")
            print(f"   ‚Ä¢ Dura√ß√£o: {transcription.duration/60:.1f} minutos")
            print(f"   ‚Ä¢ Palavras: {len(transcription.words):,}")
            print(f"   ‚Ä¢ Tecnologias: {len(analysis.tecnologias_mencionadas)}")
            print(f"   ‚Ä¢ Conceitos: {len(analysis.conceitos_importantes)}")
            
            return result
            
        except Exception as e:
            print(f"‚ùå ERRO NO PROCESSAMENTO: {e}")
            return {"status": "error", "message": str(e)}

    def batch_process_videos(self, videos_dir: str = "videos", start_modulo: int = 1) -> List[Dict[str, Any]]:
        """Processa todos os v√≠deos em lote"""
        print(f"\n{'='*60}")
        print(f"üé¨ PROCESSAMENTO EM LOTE - {videos_dir}")
        print(f"{'='*60}")
        
        # Extens√µes de v√≠deo suportadas
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm', '.m4v']
        results = []
        
        if not os.path.exists(videos_dir):
            print(f"‚ùå Diret√≥rio {videos_dir} n√£o encontrado")
            return results
            
        # Encontrar todos os v√≠deos
        video_files = []
        for ext in video_extensions:
            video_files.extend(Path(videos_dir).glob(f"**/*{ext}"))
        
        if not video_files:
            print(f"‚ùå Nenhum v√≠deo encontrado em {videos_dir}")
            return results
            
        # Ordenar por nome
        video_files = sorted(video_files)
        
        print(f"üìπ Encontrados {len(video_files)} v√≠deos para processar")
        print("üìÅ V√≠deos encontrados:")
        for i, video in enumerate(video_files, 1):
            print(f"   {i:2d}. {video.name}")
        
        # Processar cada v√≠deo
        for i, video_path in enumerate(video_files, 1):
            print(f"\n{'='*60}")
            print(f"üé¨ V√çDEO {i}/{len(video_files)}: {video_path.name}")
            print(f"{'='*60}")
            
            # Determinar m√≥dulo e aula
            modulo = start_modulo
            aula = i
            
            # Tentar extrair n√∫meros do nome do arquivo
            filename = video_path.stem
            modulo_match = re.search(r'modulo[-_]?(\d+)', filename, re.IGNORECASE)
            aula_match = re.search(r'aula[-_]?(\d+)', filename, re.IGNORECASE)
            
            if modulo_match:
                modulo = int(modulo_match.group(1))
            if aula_match:
                aula = int(aula_match.group(1))
            
            print(f"üìä Processando como: M√≥dulo {modulo}, Aula {aula}")
            
            result = self.process_video_complete(str(video_path), modulo, aula)
            result['video_info'] = {
                'filename': video_path.name,
                'modulo': modulo,
                'aula': aula,
                'index': i
            }
            results.append(result)
            
            # Pequena pausa entre processamentos
            if i < len(video_files):
                print("‚è≥ Aguardando 3 segundos...")
                time.sleep(3)
        
        # Relat√≥rio final
        print(f"\n{'='*60}")
        print(f"üìä RELAT√ìRIO FINAL - PROCESSAMENTO EM LOTE")
        print(f"{'='*60}")
        
        successful = [r for r in results if r.get("status") == "success"]
        failed = [r for r in results if r.get("status") == "error"]
        
        print(f"‚úÖ Sucessos: {len(successful)}")
        print(f"‚ùå Falhas: {len(failed)}")
        
        if successful:
            print(f"\nüìÅ Aulas criadas com sucesso:")
            for result in successful:
                info = result.get('video_info', {})
                print(f"   ‚Ä¢ {info.get('filename', 'N/A')} ‚Üí {result.get('output_dir', 'N/A')}")
                
        if failed:
            print(f"\n‚ùå V√≠deos que falharam:")
            for result in failed:
                info = result.get('video_info', {})
                print(f"   ‚Ä¢ {info.get('filename', 'N/A')}: {result.get('message', 'Erro desconhecido')}")
        
        return results

# --- FUN√á√ÉO PRINCIPAL ---

def main():
    """Fun√ß√£o principal com compatibilidade total"""
    
    # Verificar se √© chamada no modo original (transcribe.py compatibility)
    if len(sys.argv) == 2 and not sys.argv[1].startswith('--'):
        # Modo compatibilidade com transcribe.py original
        video_file = sys.argv[1]
        if os.path.exists(video_file):
            print("üîÑ Modo compatibilidade - usando fun√ß√£o original")
            result = transcribe_video_original(video_file)
            if result:
                sys.exit(0)
            else:
                sys.exit(1)
        else:
            print(f"Erro: O arquivo de v√≠deo n√£o foi encontrado em '{video_file}'")
            sys.exit(1)
    
    # Modo enhanced
    if len(sys.argv) < 2:
        print("""
ü§ñ Sistema Avan√ßado de Transcri√ß√£o e An√°lise de V√≠deos Educacionais

MODOS DE USO:

1. MODO LEGADO (compat√≠vel com transcribe.py):
   python transcribe.py video.mp4
   
2. MODO COMPLETO (transcri√ß√£o + an√°lise + documenta√ß√£o):
   python transcribe.py --complete video.mp4 [modulo] [aula]
   
3. MODO LOTE (processar pasta inteira):
   python transcribe.py --batch [pasta_videos] [modulo_inicial]

EXEMPLOS:
   python transcribe.py videos/aula01.mp4              # Modo legado
   python transcribe.py --complete videos/aula01.mp4 1 1    # Modo completo
   python transcribe.py --batch videos 1                     # Lote
   python transcribe.py --batch                              # Lote pasta padr√£o

VARI√ÅVEIS DE AMBIENTE:
   GROQ_API_KEY    - Obrigat√≥ria para transcri√ß√£o
   GEMINI_API_KEY  - Opcional para an√°lise inteligente
   
ESTRUTURA DE ARQUIVOS:
   videos/         - Coloque seus v√≠deos aqui
   modulo-XX/      - Aulas organizadas ser√£o criadas aqui
   temp/           - Arquivos tempor√°rios
        """)
        sys.exit(1)
    
    try:
        system = EnhancedTranscriptionSystem()
        
        command = sys.argv[1]
        
        if command == "--batch":
            # Processamento em lote
            videos_dir = sys.argv[2] if len(sys.argv) > 2 else "videos"
            start_modulo = int(sys.argv[3]) if len(sys.argv) > 3 else 1
            
            results = system.batch_process_videos(videos_dir, start_modulo)
            
            # Determinar c√≥digo de sa√≠da
            successful = len([r for r in results if r.get("status") == "success"])
            if successful > 0:
                sys.exit(0)
            else:
                sys.exit(1)
                
        elif command == "--complete":
            # Processamento completo individual
            if len(sys.argv) < 3:
                print("‚ùå Modo completo requer pelo menos o caminho do v√≠deo")
                sys.exit(1)
                
            video_path = sys.argv[2]
            modulo = int(sys.argv[3]) if len(sys.argv) > 3 else 1
            aula = int(sys.argv[4]) if len(sys.argv) > 4 else 1
            
            if not os.path.exists(video_path):
                print(f"‚ùå Arquivo n√£o encontrado: {video_path}")
                sys.exit(1)
                
            result = system.process_video_complete(video_path, modulo, aula)
            
            if result.get("status") == "success":
                sys.exit(0)
            else:
                print(f"‚ùå Erro no processamento: {result.get('message')}")
                sys.exit(1)
        else:
            print(f"‚ùå Comando n√£o reconhecido: {command}")
            print("Use --help para ver os comandos dispon√≠veis")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Processamento interrompido pelo usu√°rio")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå Erro fatal: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()